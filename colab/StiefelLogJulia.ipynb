{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StiefelLogJulia.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnguyend/StiefelGeodesic/blob/main/colab/StiefelLogJulia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1r1bbb0yBv"
      },
      "source": [
        "# <img src=\"https://github.com/JuliaLang/julia-logo-graphics/raw/master/images/julia-logo-color.png\" height=\"100\" /> _Colab Notebook For Stiefel Logarithm_\n",
        "\n",
        "## Work book showing the algorithms for Riemannian Logarithms on Stiefel manifolds - with a family of metrics - the algorithm works for both embedded and canonical metrics - and beyond.\n",
        "\n",
        "## Including: implementation of Frechet derivatives (previously not available in Julia - function is expm_frechet_algo_64)\n",
        "\n",
        "## Numerical verification of frechet derivatives as directional derivative, trace formula for Frechet derivatives\n",
        "\n",
        "## simple implementation of the exponential map for Stiefel manifold, both versions in our paper.\n",
        "\n",
        "## Detailed implementation and verification of all steps in the paper\n",
        "\n",
        "## use rlog_descent for the gradient descent algorithm, rlog_lbfgs for lbfgs algorithm.\n",
        "\n",
        "\n",
        "## Instructions\n",
        "1. Work on a copy of this notebook: _File_ > _Save a copy in Drive_ (you will need a Google account). Alternatively, you can download the notebook using _File_ > _Download .ipynb_, then upload it to [Colab](https://colab.research.google.com/).\n",
        "2. If you need a GPU: _Runtime_ > _Change runtime type_ > _Harware accelerator_ = _GPU_.\n",
        "3. Execute the following cell (click on it and press Ctrl+Enter) to install Julia, IJulia and other packages (if needed, update `JULIA_VERSION` and the other parameters). **This takes a couple of minutes.**\n",
        "4. **Reload this page (press Ctrl+R, or ⌘+R, or the F5 key) and continue to the next section.**\n",
        "\n",
        "_Notes_:\n",
        "* If your Colab Runtime gets reset (e.g., due to inactivity), repeat steps 2, 3 and 4.\n",
        "* After installation, if you want to change the Julia version or activate/deactivate the GPU, you will need to reset the Runtime: _Runtime_ > _Factory reset runtime_ and repeat steps 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIeFXS0F0zww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e2f145-07cf-4112-e6ef-a7165a421043"
      },
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.6.0\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools Plots\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -n \"$COLAB_GPU\" ] && [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  if [ \"$COLAB_GPU\" = \"1\" ]; then\n",
        "      JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia  \n",
        "\n",
        "  echo ''\n",
        "  echo \"Success! Please reload this page and jump to the next section.\"\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing Julia 1.6.0 on the current Colab Runtime...\n",
            "2021-08-24 11:39:21 URL:https://storage.googleapis.com/julialang2/bin/linux/x64/1.6/julia-1.6.0-linux-x86_64.tar.gz [112838927/112838927] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing Julia package IJulia...\n",
            "Installing Julia package BenchmarkTools...\n",
            "Installing Julia package Plots...\n",
            "Installing IJulia kernel...\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mInstalling julia kernelspec in /root/.local/share/jupyter/kernels/julia-1.6\n",
            "\n",
            "Success! Please reload this page and jump to the next section.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OS3Ac017T1i"
      },
      "source": [
        "# Checking the Installation\n",
        "**REMEMBER TO LOAD THE PAGE BY RUNNING F5 IF the following command does not work**\n",
        "\n",
        "The `versioninfo()` function should print your Julia version and some other info about the system:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEzvvzCl1i0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f94a7ce-a428-421b-dd2a-41b6b36f7428"
      },
      "source": [
        "versioninfo()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Julia Version 1.6.0\n",
            "Commit f9720dc2eb (2021-03-24 12:55 UTC)\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-pc-linux-gnu)\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-11.0.1 (ORCJIT, haswell)\n",
            "Environment:\n",
            "  JULIA_NUM_THREADS = 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEqeweODYnq7"
      },
      "source": [
        "# CHECK EXECUTION of EXPM - Julia does not have EXPM_FRECHET.\n",
        "We will port from scipy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQlpeR9wNOi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370b9b6e-9610-4133-afc4-d957adbb0a4d"
      },
      "source": [
        "using BenchmarkTools\n",
        "\n",
        "using LinearAlgebra\n",
        "# using Base.LinAlg\n",
        "A = rand(1000, 1000)\n",
        "A = A - A'\n",
        "@benchmark exp(A)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 5 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.046 s\u001b[22m\u001b[39m … \u001b[35m   1.332 s\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 2.26% … 21.07%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.151 s               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m12.10%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.172 s\u001b[22m\u001b[39m ± \u001b[32m129.641 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m12.14% ±  9.61%\n",
              "\n",
              "  \u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\n",
              "  1.05 s\u001b[90m         Histogram: frequency by time\u001b[39m         1.05 s \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m167.86 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m47\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo3ga83r-lPw",
        "outputId": "171632e2-dac4-440f-fce5-0038354d4ba5"
      },
      "source": [
        "function logom(U)\n",
        "   v, V = eigen(U)\n",
        "    return real(V*broadcast(*, log.(v), V'))\n",
        "end\n",
        "for i in 1:10\n",
        "  n = 1000\n",
        "  A = rand(n, n)\n",
        "  A = A - A'\n",
        "  U = exp(A)\n",
        "  X = logom(U)\n",
        "  println(linf(exp(X) - U))\n",
        "end"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6706529349107555e-11\n",
            "7.66508384542064e-12\n",
            "1.3862403412667756e-11\n",
            "1.3088582301312712e-11\n",
            "4.374465720213827e-11\n",
            "3.155618561595519e-11\n",
            "4.4705732171745893e-11\n",
            "2.878959570740136e-11\n",
            "7.443969052278732e-12\n",
            "8.389938049857548e-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvMMT26C_Xoz",
        "outputId": "90a8b667-072e-4356-ddbd-de918fdae8e0"
      },
      "source": [
        "@benchmark logom(U)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 2 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m3.690 s\u001b[22m\u001b[39m … \u001b[35m  3.714 s\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.07% … 0.12%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m3.702 s              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.10%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m3.702 s\u001b[22m\u001b[39m ± \u001b[32m17.040 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.10% ± 0.03%\n",
              "\n",
              "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[39m \u001b[39m \n",
              "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m \u001b[39m▁\n",
              "  3.69 s\u001b[90m         Histogram: frequency by time\u001b[39m        3.71 s \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m69.74 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m30\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrMBYPD5_XnP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUEZNE5Dcuqk",
        "outputId": "95fe5061-78c8-4efd-fbc9-eb68d361b75a"
      },
      "source": [
        "ell_table_61 = (\n",
        "        nothing,\n",
        "        # 1\n",
        "        2.11e-8,\n",
        "        3.56e-4,\n",
        "        1.08e-2,\n",
        "        6.49e-2,\n",
        "        2.00e-1,\n",
        "        4.37e-1,\n",
        "        7.83e-1,\n",
        "        1.23e0,\n",
        "        1.78e0,\n",
        "        2.42e0,\n",
        "        # 11\n",
        "        3.13e0,\n",
        "        3.90e0,\n",
        "        4.74e0,\n",
        "        5.63e0,\n",
        "        6.56e0,\n",
        "        7.52e0,\n",
        "        8.53e0,\n",
        "        9.56e0,\n",
        "        1.06e1,\n",
        "        1.17e1,\n",
        "        )\n",
        "function _diff_pade3(A, E)\n",
        "    b = (120., 60., 12., 1.)\n",
        "    A2 = A * A\n",
        "    M2 = A * E + E*A\n",
        "    U = A * (b[4]*A2 + UniformScaling(b[2]))\n",
        "    V = b[3]*A2 + UniformScaling(b[1])\n",
        "    Lu = A * (b[3]*M2) + E * (b[3]*A2 + UniformScaling(b[1]))\n",
        "    Lv = b[3] .* M2\n",
        "    return U, V, Lu, Lv\n",
        "end        \n",
        "\n",
        "function _diff_pade5(A, E)\n",
        "    b = (30240., 15120., 3360., 420., 30., 1.)\n",
        "    A2 = A * A\n",
        "    M2 = A * E + E * A\n",
        "    A4 = A2 * A2\n",
        "    M4 = A2 * M2 + M2 * A2\n",
        "    U = A * (b[6]*A4 + b[4]*A2 + UniformScaling(b[2]))\n",
        "    V = b[5]*A4 + b[3]*A2 + UniformScaling(b[1])\n",
        "    Lu = (A * (b[6]*M4 + b[4]*M2) +\n",
        "            E * (b[6]*A4 + b[4]*A2 + UniformScaling(b[2])))\n",
        "    Lv = b[5]*M4 + b[3]*M2\n",
        "    return U, V, Lu, Lv\n",
        "end\n",
        "\n",
        "function _diff_pade7(A, E)\n",
        "    b = (17297280., 8648640., 1995840., 277200., 25200., 1512., 56., 1.)\n",
        "    A2 = A * A\n",
        "    M2 = A * E + E * A\n",
        "    A4 = A2 * A2\n",
        "    M4 = A2 * M2 + M2 * A2\n",
        "    A6 = A2 * A4\n",
        "    M6 = A4 * M2 + M4 * A2\n",
        "    U = A * (b[8]*A6 + b[6]*A4 + b[4]*A2 + UniformScaling(b[2]))\n",
        "    V = b[7]*A6 + b[5]*A4 + b[3]*A2 + UniformScaling(b[1])\n",
        "    Lu = (A*(b[8]*M6 + b[6]*M4 + b[4]*M2) +\n",
        "            E*(b[8]*A6 + b[6]*A4 + b[4]*A2 + UniformScaling(b[2])))\n",
        "    Lv = b[7]*M6 + b[5]*M4 + b[3]*M2\n",
        "    return U, V, Lu, Lv\n",
        "end\n",
        "\n",
        "function _diff_pade9(A, E)\n",
        "    b = (17643225600., 8821612800., 2075673600., 302702400., 30270240.,\n",
        "            2162160., 110880., 3960., 90., 1.)\n",
        "    A2 = A * A\n",
        "    M2 = A * E + E * A\n",
        "    A4 = A2 * A2\n",
        "    M4 = A2 * M2 + M2 * A2\n",
        "    A6 = A2 * A4\n",
        "    M6 = A4 * M2 + M4 * A2\n",
        "    A8 = A4 * A4\n",
        "    M8 = A4 * M4 + M4 * A4\n",
        "    U = A * (b[10]*A8 + b[8]*A6 + b[6]*A4 + b[4]*A2 + UniformScaling(b[2]))\n",
        "    V = b[9]*A8 + b[7]*A6 + b[5]*A4 + b[3]*A2 + UniformScaling(b[1])\n",
        "    Lu = (A *(b[10]*M8 + b[8]*M6 + b[6]*M4 + b[4]*M2) +\n",
        "            E * (b[10]*A8 + b[8]*A6 + b[6]*A4 + b[4]*A2 + UniformScaling(b[2])))\n",
        "    Lv = b[9]*M8 + b[7]*M6 + b[5]*M4 + b[3]*M2\n",
        "    return U, V, Lu, Lv\n",
        "end\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_diff_pade9 (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge2Ml_8FyoCl",
        "outputId": "17ed4bf6-ed30-459f-941d-6f58b5db41b0"
      },
      "source": [
        "function norm_axes(A, axes)\n",
        "  return sqrt.(sum!(Vector{Float64}(undef, size(A, 1)), A .* A))\n",
        "end\n",
        "\n",
        "function expm_frechet_algo_64(A, E)\n",
        "    n = size(A, 1)\n",
        "    s = nothing    \n",
        "    A_norm_1 = norm(A, 1)\n",
        "    m_pade_pairs = (\n",
        "            (3, _diff_pade3),\n",
        "            (5, _diff_pade5),\n",
        "            (7, _diff_pade7),\n",
        "            (9, _diff_pade9))\n",
        "    for m_pade in m_pade_pairs\n",
        "        m, pade = m_pade\n",
        "        if A_norm_1 <= ell_table_61[m]\n",
        "            U, V, Lu, Lv = pade(A, E)\n",
        "            s = 0\n",
        "            break\n",
        "        end            \n",
        "    end\n",
        "    if isnothing(s)\n",
        "        # scaling\n",
        "        s = max(0, Int(ceil(log2(A_norm_1 / ell_table_61[13]))))\n",
        "        A = (2.0^-s) * A\n",
        "        E = (2.0^-s) * E \n",
        "        # pade order 13\n",
        "        A2 = A * A\n",
        "        M2 = A * E + E * A\n",
        "        A4 = A2 * A2\n",
        "        M4 = A2 * M2 + M2 * A2\n",
        "        A6 = A2 * A4\n",
        "        M6 = A4 * M2 + M4 * A2\n",
        "        b = (64764752532480000., 32382376266240000., 7771770303897600.,\n",
        "                1187353796428800., 129060195264000., 10559470521600.,\n",
        "                670442572800., 33522128640., 1323241920., 40840800., 960960.,\n",
        "                16380., 182., 1.)\n",
        "        W1 = b[14]*A6 + b[12]*A4 + b[10]*A2\n",
        "        W2 = b[8]*A6 + b[6]*A4 + b[4]*A2 + UniformScaling(b[2])\n",
        "        Z1 = b[13]*A6 + b[11]*A4 + b[9]*A2\n",
        "        Z2 = b[7]*A6 + b[5]*A4 + b[3]*A2 + UniformScaling(b[1])\n",
        "        W = A6 * W1 + W2\n",
        "        U = A * W\n",
        "        V = A6 * Z1 + Z2\n",
        "        Lw1 = b[14]*M6 + b[12]*M4 + b[10]*M2\n",
        "        Lw2 = b[8]*M6 + b[6]*M4 + b[4]*M2\n",
        "        Lz1 = b[13]*M6 + b[11]*M4 + b[9]*M2\n",
        "        Lz2 = b[7]*M6 + b[5]*M4 + b[3]*M2\n",
        "        Lw = A6 * Lw1 + M6 * W1 + Lw2\n",
        "        Lu = A * Lw + E * W\n",
        "        Lv = A6 * Lz1 + M6 * Z1 + Lz2\n",
        "    end        \n",
        "    # factor once and solve twice\n",
        "    lu_piv = lu(-U + V)\n",
        "    R = lu_piv \\ (U + V)\n",
        "    L = lu_piv \\ (Lu + Lv + (Lu - Lv)* R)\n",
        "    # squaring\n",
        "    for k in 1:s\n",
        "        L = R * L + L * R\n",
        "        R = R * R\n",
        "    end\n",
        "    return R, L\n",
        "end"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "expm_frechet_algo_64 (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlAo0oFeY7jS"
      },
      "source": [
        "## NOW TEST expm_frechet_algo_64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdniGvPUA7k7",
        "outputId": "55994bd7-2f9e-45ea-89da-b2bfda8c4666"
      },
      "source": [
        "n = 5\n",
        "A = randn(n, n)\n",
        "E = randn(n, n)\n",
        "pp = expm_frechet_algo_64(A, E)\n",
        "println(pp[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0060109754371573 -2.537360492724837 1.5102593862800624 2.7007006389200146 -0.9159775192490337; 2.7483322334494105 2.9954445501467486 2.2277889088533573 2.55987326251544 0.780954247371168; 0.08231076935810337 -1.0801238471596377 0.5108818696333359 1.1516535604769988 -0.4948580414097984; -0.7432634706397881 -3.1498608935805144 -0.03368432980302584 1.105916827935206 -1.1994727437587096; -0.8959621069409777 2.2463198874402726 -0.826468311258394 -0.4092355089758429 1.6584545012602825]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kr6C7NfSS6s",
        "outputId": "98bfe7ec-5bd4-4a77-dbea-61e13118e7a9"
      },
      "source": [
        "n = 100\n",
        "A = 0.1*(reshape(0:(n*n-1), n, n)' .% 7) + UniformScaling(0.5)\n",
        "E = reshape(0:(n*n-1), n, n)'\n",
        "# E = E .* E\n",
        "E = (E .* E) .% 23\n",
        "\n",
        "println(A)\n",
        "println(E)\n",
        "if false\n",
        "  @benchmark expm_frechet_algo_64(A, E)\n",
        "end\n",
        "# println(_diff_pade9(A, E))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004; 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 1.1 0.0 0.1 0.2 0.30000000000000004 0.4 0.5; 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.7 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0; 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 1.0 0.6000000000000001 0.0 0.1 0.2; 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.6 0.2 0.30000000000000004 0.4; 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.9 0.5 0.6000000000000001; 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.5 0.1; 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.30000000000000004 0.4 0.5 0.6000000000000001 0.0 0.1 0.2 0.8]\n",
            "[0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3; 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18; 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0; 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18; 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3; 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1; 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12; 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13; 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4; 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8; 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2; 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9; 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6; 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16; 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16; 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6; 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9; 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2; 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8; 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4; 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13; 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12; 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1; 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3; 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18; 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0; 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18; 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3; 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1; 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12; 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13; 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4; 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8; 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2; 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9; 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6; 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16; 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16; 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6; 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9; 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2; 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8; 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4; 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13; 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12; 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1; 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3; 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18; 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0; 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18; 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3; 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1; 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12; 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13; 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4; 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8; 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2; 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9; 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6; 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16; 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16; 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6; 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9; 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2; 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8; 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4; 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13; 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12; 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1; 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3; 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18; 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0; 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18; 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3; 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1; 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12; 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13; 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4; 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8; 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2; 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9; 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6; 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16; 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16; 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6; 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9; 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2; 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8; 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4; 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13; 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12; 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1; 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3; 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18; 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0; 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18; 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3; 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1; 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12; 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13 2 16 9 4 1 0 1 4 9 16 2 13 3 18 12 8 6 6 8 12 18 3 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgiDYGruYX5N",
        "outputId": "bc74d02b-c80d-4e6d-8e52-bffcca54b8e9"
      },
      "source": [
        "@benchmark expm_frechet_algo_64(A, E)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 619 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m6.306 ms\u001b[22m\u001b[39m … \u001b[35m27.280 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 16.65%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m6.822 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m8.029 ms\u001b[22m\u001b[39m ± \u001b[32m 2.744 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m12.59% ± 16.37%\n",
              "\n",
              "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▂\n",
              "  7.67 ms\u001b[90m        Histogram: frequency by time\u001b[39m        7.48 ms \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m8.63 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m258\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZaWlNkiuGJT"
      },
      "source": [
        "# VERIFY FRECHET DERIVATIVE AND THE TRACE FORMULA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTqU4AzruLJW",
        "outputId": "0d9de4bf-dc50-41e7-82af-fd09cf6be9ff"
      },
      "source": [
        "function linf(mat)\n",
        "  return maximum(abs.(mat))\n",
        "end  \n",
        "\n",
        "n = 5\n",
        "A = 0.1*(reshape(0:(n*n-1), n, n)' .% 7) + UniformScaling(0.5)\n",
        "E = reshape(0:(n*n-1), n, n)'\n",
        "# E = E .* E\n",
        "E = (E .* E) .% 23\n",
        "\n",
        "e1 = exp(A)\n",
        "dlt = 1e-8\n",
        "e2 = exp(A + dlt*E)\n",
        "println(\"VERIFYING FRECHET DERIVATIVE\")\n",
        "(e2-e1)/dlt\n",
        "# expm_frechet_algo_64(A, E)[2]\n",
        "println(linf((e2-e1)/dlt - expm_frechet_algo_64(A, E)[2]))\n",
        "\n",
        "println(\"VERIFYING THE TRACE FORMULA\")\n",
        "C = randn(n, n)\n",
        "D = randn(n, n)\n",
        "println(tr(C*expm_frechet_algo_64(A, E)[2]*D))\n",
        "println(tr(expm_frechet_algo_64(A, D*C)[2]*E))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VERIFYING FRECHET DERIVATIVE\n",
            "1.4476886747161188e-5\n",
            "VERIFYING THE TRACE FORMULA\n",
            "48.066842252764786\n",
            "48.066842252764786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ_ISUQEZHT3"
      },
      "source": [
        "# Code simple Stiefel manifold with geodesic, random point, random tangent vector, exponential map (both versions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gUTneefqWEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa1e769-467f-4f98-98a5-6edd73a8240e"
      },
      "source": [
        "struct Stf\n",
        "  n::Int64\n",
        "  p::Int64\n",
        "  alpha::Vector{Float64}\n",
        "end\n",
        "\n",
        "function stf_rand(M)\n",
        "  ## Random point on the manifold M\n",
        "  QR = qr(randn(M.n, M.p))\n",
        "  return QR.Q * vcat(I, zeros((M.n-M.p, M.p)))\n",
        "end\n",
        "\n",
        "function stf_inner(M, Y, eta, xi)\n",
        "  # inner product\n",
        "  return M.alpha[1]*sum(eta .* xi) + (M.alpha[2] - M.alpha[1])*sum((eta' * Y) .* (xi' * Y))\n",
        "end\n",
        "\n",
        "function linf(mat)\n",
        "  return maximum(abs.(mat))\n",
        "end  \n",
        "\n",
        "function logom(U)\n",
        "  # log for orthogonal matrices\n",
        "  # cost only 3 times exp\n",
        "   v, V = eigen(U)\n",
        "    return real(V*broadcast(*, log.(v), V'))\n",
        "end\n",
        "\n",
        "function sym(mat)\n",
        "  return 0.5*(mat + mat')\n",
        "end\n",
        "\n",
        "function asym(mat)\n",
        "  return 0.5*(mat - mat')\n",
        "end\n",
        "\n",
        "function stf_proj(M, Y, omg)\n",
        "  # projection of an ambient vector omg to the tangent space at Y  \n",
        "  return omg - Y*sym(Y'*omg)\n",
        "end\n",
        "\n",
        "function stf_randvec(M, Y)\n",
        "  # random tangent vector at Y\n",
        "  r = stf_proj(M, Y, randn(size(Y)))\n",
        "  return r ./ sqrt(stf_inner(M, Y, r, r))\n",
        "end\n",
        "\n",
        "function get_Q(Y, Y1)\n",
        "    \"\"\" algorithm: find a basis in linear span of Y Y1\n",
        "    orthogonal to Y\n",
        "    \"\"\"\n",
        "    n , p = size(Y)\n",
        "    F = svd([Y Y1])\n",
        "    k = sum(F.S .> 1e-14)\n",
        "    good = F.U[:, 1:k]*F.Vt[1:k, 1:k]\n",
        "    qs = nullspace(Y'*good)\n",
        "    QR = qr(good*qs)\n",
        "    return QR.Q * vcat(I, zeros((n-k+p, k - p)))\n",
        "end\n",
        "\n",
        "function sexp(M, Y, Q, A, R )\n",
        "  # exponential map, given Y, Q\n",
        "  alf = M.alpha[2]/M.alpha[1]\n",
        "  # println(alf)\n",
        "  p, k  = size(Y, 2), size(Q, 2)\n",
        "  ex1 = exp((1-2*alf)*A)\n",
        "  ex2 = exp(\n",
        "      vcat([2*alf*A -R'], [R zeros((k, k))]))\n",
        "  return Y*ex2[1:p, 1:p]*ex1 + Q*ex2[(p+1):end, 1:p]*ex1  \n",
        "end\n",
        "\n",
        "function stf_exp(M, Y, eta)\n",
        "  # exponential map\n",
        "  p = size(Y, 2)\n",
        "  A = Y' * eta\n",
        "  QR = qr(eta - Y * A)\n",
        "  return sexp(M, Y, QR.Q* vcat(I, zeros((M.n-M.p, M.p))), A, QR.R)\n",
        "end \n",
        "\n",
        "\n",
        "function Pi0(Y, a)\n",
        "  return a - Y*(Y'*a)\n",
        "end  \n",
        "\n",
        "function stf_gamma(M, Y, xi, eta)\n",
        "    # the Christoffel term in the geodesic equation\n",
        "    al = M.alpha[2]/M.alpha[1]    \n",
        "    return Y*sym(xi' * eta) + (1-al)*Pi0(Y, xi*(eta'*Y) + eta*(xi'*Y))\n",
        "end\n",
        "\n",
        "function stf_dot_exp(M, X, eta, t)\n",
        "   # return the other exp formula, and also\n",
        "   # time derivative of the exponential map\n",
        "   alf = M.alpha[2]/M.alpha[1]\n",
        "   p = M.p\n",
        "   A = X' * eta\n",
        "\n",
        "   e_mat = zeros(2*p, 2*p)\n",
        "   e_mat[1:p, 1:p] = (2*alf-1)*A \n",
        "   e_mat[1:p, p+1:end] = -eta'*eta - 2*(1-alf)*A*A\n",
        "   e_mat[p+1:end, 1:p] = I(p)\n",
        "   e_mat[p+1:end, p+1:end] = A\n",
        "   eE = exp(t*e_mat)\n",
        "   eA = exp((1-2*alf)*t*A)\n",
        "   ex = ([X eta] * eE)[1:end, 1:p] * eA\n",
        "   dot_ex = (vcat([X eta]) * e_mat*eE)[1:end, 1:p] * eA +\n",
        "            (vcat([X eta]) * eE)[1:end, 1:p] * ((1-2*alf)*A*eA)\n",
        "   return ex, dot_ex\n",
        "end\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "stf_dot_exp (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbFZQMe4d0zs"
      },
      "source": [
        "## TEST THE EXPONENTIAL MAP. THREE CONDITIONS: $Y(t)$ is on the manifold, and $d/dt Y(0) = \\eta$. Check the geodesic equation. Verifying both formulas and time derivative of geodesic equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZfDukF12Vg9",
        "outputId": "e0975cf6-321d-4615-ad88-efd12297713d"
      },
      "source": [
        "n = 7\n",
        "p = 3\n",
        "alpha = [1, .8]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = stf_rand(M2)\n",
        "Y1 = stf_rand(M2)\n",
        "eta = stf_randvec(M2, Y)\n",
        "\n",
        "Yt = stf_exp(M2, Y, eta)\n",
        "\n",
        "println(\"check Yt is on the manifold\")\n",
        "println(linf(Yt'*Yt - I(p)))\n",
        "dlt = 1e-8\n",
        "e2 = stf_exp(M2, Y, dlt*eta)\n",
        "println(\"check d/dt Yt is eta\")\n",
        "println(linf(eta - (e2-Y)/dlt))\n",
        "\n",
        "# check the geodesic equation Y\n",
        "dlt = 1e-5\n",
        "t = 1.5\n",
        "Yt = stf_exp(M2, Y, t*eta)\n",
        "Ytp = stf_exp(M2, Y, (t+dlt)*eta)\n",
        "Ytm = stf_exp(M2, Y, (t-dlt)*eta)\n",
        "\n",
        "println(\"VERIYING THE GEODESIC EQUATION d/dt Yt is eta\")\n",
        "Ydt = (Ytp - Ytm)/dlt/2\n",
        "Yddt = (Ytp + Ytm - 2*Yt)/dlt/dlt\n",
        "println(linf(Yddt + stf_gamma(M2, Yt, Ydt, Ydt)))\n",
        "\n",
        "Yt1, Ytd1 = stf_dot_exp(M2, Y, eta, t)\n",
        "println(\"VERIYING FORMULA 3.3 and also the time derivative of geodesic\")\n",
        "println(linf(Yt1 - Yt))\n",
        "println(linf(Ytd1 - Ydt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check Yt is on the manifold\n",
            "2.220446049250313e-16\n",
            "check d/dt Yt is eta\n",
            "1.1344022082804273e-8\n",
            "VERIYING THE GEODESIC EQUATION d/dt Yt is eta\n",
            "5.058922321360404e-6\n",
            "VERIYING FORMULA 3.3 and also the time derivative of geodesic\n",
            "2.393918396847994e-16\n",
            "1.2182581332620401e-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKn0io0rcN1D",
        "outputId": "7944c001-e96c-4625-985b-648cd80ee8ae"
      },
      "source": [
        "@benchmark stf_exp(M2, Y, eta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m27.444 μs\u001b[22m\u001b[39m … \u001b[35m 6.083 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m33.587 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m38.908 μs\u001b[22m\u001b[39m ± \u001b[32m89.711 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m2.50% ± 1.91%\n",
              "\n",
              "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
              "  165 μs\u001b[90m          Histogram: frequency by time\u001b[39m          32 μs \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m20.53 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m94\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyqcctpJwZNE"
      },
      "source": [
        "# CHECK FORMULA FOR THE COST FUNCTION. VERIFY \n",
        "\n",
        " $1/2\\|Y(t) - Z\\|^2 - p = \\mathrm{Tr} (Z^T[Y Q] \\exp \\hat{A} I_{p+k, p}\\exp((1-2\\alpha)A)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuEMnxFhaC4r",
        "outputId": "110b9c50-d6fc-4cef-d349-f8849c50271b"
      },
      "source": [
        "xi = stf_randvec(M2, Y)\n",
        "Z = stf_exp(M2, Y, xi)\n",
        "Q = get_Q(Y, Z)\n",
        "\n",
        "k = size(Q)[2]\n",
        "# now take a guess\n",
        "\n",
        "A = asym(randn(p, p))\n",
        "R = randn(k, p)\n",
        "eta = Y*A + Q*R\n",
        "\n",
        "Yt = stf_exp(M2, Y, eta)\n",
        "println(\"VERIFYING THE COST FUNCTION FORMULA\")\n",
        "\n",
        "cost0 = 0.5*sum((Yt - Z).*(Yt - Z)) - p\n",
        "println(cost0)\n",
        "\n",
        "fix = (Z'*[Y Q])'\n",
        "alf = M2.alpha[2]/M2.alpha[1]\n",
        "\n",
        "Ahat = vcat([2*alf*A -R'], [R zeros((k, k))])\n",
        "cost1 = -sum(fix .* (exp(Ahat)[1:end, 1:p]* exp((1-2*alf)*A)))\n",
        "println(cost1)\n",
        "\n",
        "ZTY = Z'*Y\n",
        "ZTQ = Z'*Q\n",
        "\n",
        "function fun(A, R)\n",
        "  # to make this cheap, ie p^3 cost only evaluate ZTY, ZTQ outside\n",
        "  # and evaluate both function and gradient\n",
        "    ex1 = exp((1-2*alf)*A)\n",
        "\n",
        "    mat = vcat([(2*alf*A) -R'], [R zeros(k, k)])\n",
        "    E = vcat([(ex1 * ZTY) ex1*ZTQ], zeros(k, p+k))\n",
        "\n",
        "    ex2, fe2 = expm_frechet_algo_64(mat, E)\n",
        "    M = ex2[1:p, 1:p]\n",
        "    N = ex2[p+1:end, 1:p]\n",
        "    ZYMQN = ZTY*M+ZTQ*N\n",
        "\n",
        "    partA = asym(\n",
        "          (1-2*alf)*expm_frechet_algo_64((1-2*alf)*A, ZYMQN)[2])\n",
        "\n",
        "    partA += 2*alf*asym(fe2[1:p, 1:p])\n",
        "    partR = -(fe2[1:p, p+1:end]' - fe2[p+1:end, 1:p])\n",
        "\n",
        "    return -sum(ZYMQN' .* ex1), partA, partR\n",
        "end\n",
        "\n",
        "f, g1, g2 = fun(A, R)\n",
        "println(f)\n",
        "DA = asym(randn(size(A)))\n",
        "DR = randn(size(R))\n",
        "\n",
        "dlt = 1e-8\n",
        "\n",
        "Ytnew = sexp(M2, Y, Q, A + dlt*DA, R + dlt*DR)\n",
        "costnew = 0.5*sum((Ytnew - Z).*(Ytnew - Z)) - p\n",
        "println(\"VERIFYING THE GRADIENT FORMULA\")\n",
        "println((costnew - f)/dlt)\n",
        "println((costnew - cost0)/dlt)\n",
        "println(sum(g1 .* DA) + sum(g2 .* DR))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VERIFYING THE COST FUNCTION FORMULA\n",
            "-0.09625865207398787\n",
            "-0.09625865207398798\n",
            "-0.0962586520739892\n",
            "VERIFYING THE GRADIENT FORMULA\n",
            "-0.08771081638769829\n",
            "-0.08771094961446124\n",
            "-0.08771078811993924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8HLN-fD2yEM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9eWEH8UZ9S4",
        "cellView": "form",
        "outputId": "cee0c594-ba94-484c-e605-865744a1efc1"
      },
      "source": [
        "#@title NOT USED - JACT\n",
        "\"\"\"# A slightly different presentation of the theorem on the gradient of the cost function\n",
        "\n",
        "Here, consider the map $(A, R) \\mapsto \\exp(Y, YA +QR)$. This map is implemented as the function $sexp$ earlier. The Jacobian of $sexp$ is a map from the space of $(A, R)$s to $R^{n\\times p}$. Its adjoint is a map from $R^{n\\times p}$ back to the space of $A, R$, called $JacT$ below, with signature $JacT(M, Y, Q, A, R, \\omega)$, or $JacT(A, R, \\omega)$ for short.\n",
        "\n",
        "The gradient of the cost function $1/2\\| sexp(A, R) -Z\\|^2_2 -p$ is $JacT(A, R, sexp(A, R) -Z)$. It is given by Frechet derivative, and we could reduce it to the form in the theorem. Below we verify numerically JacT is the adjoint, ie it satisfies for all random direction $\\Delta_A, \\Delta_R$ and random $\\omega$\n",
        "$$\\lim_{\\delta\\to 0} \\frac{1}{\\delta}\\mathrm{Tr}\\omega^T(sexp(A+\\delta \\Delta_A, R + \\delta \\Delta_R) - sexp(A, R)) = JacT(A, R, \\omega)$$\n",
        "\"\"\"\n",
        "function JacT(M, Y, Q, A, R, omg)\n",
        "    p, k  = size(Y, 2), size(Q, 2)\n",
        "    alf = M.alpha[2]/M.alpha[1]\n",
        "    ex1 = exp((1-2*alf)*A)\n",
        "    K14 = vcat(hcat(ex1*omg'*Y, ex1*omg'*Q), zeros((k, p+k)))\n",
        "    \n",
        "    Q14 = expm_frechet_algo_64(vcat([2*alf*A -R'], [R zeros((k, k))]), K14)\n",
        "    \n",
        "    K23 = omg' * (Y * Q14[1][1:p, 1:p] + Q * Q14[1][(p+1):end, 1:p])\n",
        "    P23 = expm_frechet_algo_64((1-2*alf)*A, K23)[2]\n",
        "    PA = asym(-(1-2*alf)*P23 - 2*alf*Q14[2][1:p, 1:p])\n",
        "    PR =  Q14[2][1:p, (p+1):end]' - Q14[2][(p+1):end, 1:p]\n",
        "    return PA, PR\n",
        "end\n",
        "M2 = Stf(n, p, alpha)\n",
        "\n",
        "omg = randn(n, p)\n",
        "# println(n, p, size(omg))\n",
        "c1, c2 = JacT(M2, Y, Q, A, R, omg)\n",
        "ee = Y * A + Q * R\n",
        "DA = asym(randn(size(A)))\n",
        "DR = randn(size(R))\n",
        "\n",
        "dlt = 1e-8\n",
        "\n",
        "println(sum(omg .*(sexp(M2, Y, Q, A + dlt*DA, R + dlt*DR) - sexp(M2, Y, Q, A, R) )/dlt))\n",
        "println(sum(c1.*DA) + sum(c2.*DR))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-7.285244080794444\n",
            "-7.285244007682631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs9PceHx6iR8"
      },
      "source": [
        "# Implementing a simple gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWdMTzxhuFz2",
        "outputId": "6975ebf7-e5d7-464b-dec7-648e96625d3e"
      },
      "source": [
        "function rlog_descent(stf, Y, Y1, tol=1e-10)\n",
        "  alf = stf.alpha[2]/stf.alpha[1]\n",
        "  n, p = stf.n, stf.p\n",
        "\n",
        "  Q = get_Q(Y, Y1)\n",
        "  k = size(Q, 2)\n",
        "\n",
        "  eta0 = stf_proj(stf, Y, Y1-Y)\n",
        "  A = asym(Y' * eta0)\n",
        "  R = Q' * eta0 - (Q' * Y) * (Y' * eta0)\n",
        "\n",
        "  ZTY = Y1'*Y\n",
        "  ZTQ = Y1'*Q\n",
        "  function fun(A, R)\n",
        "    # to make this cheap, ie p^3 cost only evaluate ZTY, ZTQ outside\n",
        "    # and evaluate both function and gradient\n",
        "      ex1 = exp((1-2*alf)*A)\n",
        "\n",
        "      mat = vcat([(2*alf*A) -R'], [R zeros(k, k)])\n",
        "      E = vcat([(ex1 * ZTY) ex1*ZTQ], zeros(k, p+k))\n",
        "\n",
        "      ex2, fe2 = expm_frechet_algo_64(mat, E)\n",
        "      M = ex2[1:p, 1:p]\n",
        "      N = ex2[p+1:end, 1:p]\n",
        "      ZYMQN = ZTY*M+ZTQ*N\n",
        "\n",
        "      partA = asym(\n",
        "          (1-2*alf)*expm_frechet_algo_64((1-2*alf)*A, ZYMQN)[2])\n",
        "\n",
        "      partA += 2*alf*asym(fe2[1:p, 1:p])\n",
        "      partR = -(fe2[1:p, p+1:end]' - fe2[p+1:end, 1:p])\n",
        "\n",
        "      return -sum(ZYMQN' .* ex1), partA, partR\n",
        "  end\n",
        "\n",
        "   max_itr = 120\n",
        "   done = false\n",
        "   itr = 0\n",
        "   fjacs = 0\n",
        "   fvals = 0\n",
        "   scl = sqrt(n*p)\n",
        "\n",
        "   while (!done) && (itr < max_itr)\n",
        "        f, dA, dR = fun(A, R)\n",
        "        fjacs += 1\n",
        "        itr  += 1\n",
        "        # println(itr, f)\n",
        "        if max(0, f + p) < tol\n",
        "            done = true\n",
        "            break\n",
        "        else\n",
        "            dnorm = sqrt(sum(dA .* dA) + sum(dR .* dR))\n",
        "            if dnorm == 0\n",
        "                break\n",
        "            end\n",
        "            A -= dA\n",
        "            R -= dR\n",
        "        end\n",
        "  end\n",
        "  return Y*A +Q*R, itr, done, A, R, Q\n",
        "end\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rlog_descent (generic function with 2 methods)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWu1NgzT6f9a",
        "outputId": "9ff02a10-17eb-4814-b62a-a085ed886f31"
      },
      "source": [
        "n = 7\n",
        "p = 3\n",
        "alpha = [1, 0.5]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = stf_rand(M2)\n",
        "xi = stf_randvec(M2, Y)*.8*pi\n",
        "\n",
        "\n",
        "Y1 = stf_exp(M2, Y, xi)\n",
        "xi1, cnt, done, A, R, Q = rlog_descent(M2, Y, Y1, 1e-8)\n",
        "size(xi1)\n",
        "# Y'* xi1\n",
        "println(linf(stf_exp(M2, Y, xi1) - Y1))\n",
        "println(cnt)\n",
        "if false\n",
        "  @benchmark rlog_descent(M2, Y, Y1, 1e-10)\n",
        "end\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0008431637114450843\n",
            "120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X9J3ITAyC9S",
        "outputId": "88bd5aed-11a0-42bd-e253-13e1d2382650"
      },
      "source": [
        "n = 7\n",
        "p = 3\n",
        "alpha = [1, 0.5]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = vcat(I, zeros((n-p, p)))\n",
        "k = p-1\n",
        "Q = vcat(zeros(p, k), I,  zeros((n-p-k, k)))\n",
        "A = asym(reshape(1:(p*p), (p, p)))\n",
        "R = reshape((1:(p*k)) .* (1:(p*k)), (k, p)) .% 10\n",
        "xi = Y * A + Q * R\n",
        "xi = xi ./ sqrt(stf_inner(M2, Y, xi, xi))\n",
        "Y1 = stf_exp(M2, Y, xi)\n",
        "xi1, cnt, done, A, R, Q = rlog_descent(M2, Y, Y1, 1e-8)\n",
        "if true\n",
        "  # size(xi1)\n",
        "  # Y'* xi1\n",
        "  println(linf(stf_exp(M2, Y, xi1) - Y1))\n",
        "  println(cnt)\n",
        "  if true\n",
        "    @benchmark rlog_descent(M2, Y, Y1, 1e-8)\n",
        "  end\n",
        "end  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.829997139611409e-5\n",
            "7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 8515 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m416.692 μs\u001b[22m\u001b[39m … \u001b[35m 11.526 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m542.816 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m579.181 μs\u001b[22m\u001b[39m ± \u001b[32m368.115 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m2.82% ± 6.08%\n",
              "\n",
              "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\n",
              "  833 μs\u001b[90m           Histogram: frequency by time\u001b[39m          557 μs \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m263.00 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m1613\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxXU57d54LpE",
        "outputId": "366f508b-b7f7-4b32-ae99-8314b28d8c96"
      },
      "source": [
        "n = 1000\n",
        "p = 200\n",
        "alpha = [1, 0.5]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = vcat(I, zeros((n-p, p)))\n",
        "k = p-1\n",
        "Q = vcat(zeros(p, k), I,  zeros((n-p-k, k)))\n",
        "A = asym(reshape(1:(p*p), (p, p)))\n",
        "R = reshape((1:(p*k)) .* (1:(p*k)), (k, p))\n",
        "xi = Y * A + Q * R\n",
        "xi = xi ./ sqrt(stf_inner(M2, Y, xi, xi))\n",
        "Y1 = stf_exp(M2, Y, xi)\n",
        "xi1, cnt, done, A, R, Q = rlog_descent(M2, Y, Y1, 1e-8)\n",
        "if true\n",
        "  # size(xi1)\n",
        "  # Y'* xi1\n",
        "  println(linf(stf_exp(M2, Y, xi1) - Y1))\n",
        "  println(cnt)\n",
        "  if true\n",
        "    @benchmark rlog_descent(M2, Y, Y1, 1e-8)\n",
        "  end\n",
        "end  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.256545872804419e-9\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 19 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m256.675 ms\u001b[22m\u001b[39m … \u001b[35m285.644 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m3.75% … 10.06%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m267.267 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m6.62%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m268.741 ms\u001b[22m\u001b[39m ± \u001b[32m  9.286 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m6.23% ±  1.95%\n",
              "\n",
              "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\n",
              "  260 ms\u001b[90m           Histogram: frequency by time\u001b[39m          258 ms \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m162.16 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m1195\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq5eTbkwif8K",
        "outputId": "fe681316-d5c2-4e4f-c9e9-f0e34e36e3b4"
      },
      "source": [
        "n = 1500\n",
        "p = 1000\n",
        "alpha = [1, 0.5]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = stf_rand(M2)\n",
        "xi = stf_randvec(M2, Y)*.5*pi\n",
        "\n",
        "if true\n",
        "  Y1 = stf_exp(M2, Y, xi)\n",
        "  xi1, cnt, done, A, R, Q = rlog_descent(M2, Y, Y1, 1e-8)\n",
        "  println(linf(stf_exp(M2, Y, xi1) - Y1))\n",
        "  println(cnt)\n",
        "  if false\n",
        "    @benchmark rlog_descent(M2, Y, Y1, 1e-8) seconds=180\n",
        "  end\n",
        "  if true\n",
        "    @benchmark rlog_descent(M2, Y, Y1, 1e-8)\n",
        "  end\n",
        "end  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0023729652948801e-7\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 1 sample with 1 evaluation.\n",
              " Single result which took \u001b[34m43.241 s\u001b[39m (2.28% GC) to evaluate,\n",
              " with a memory estimate of \u001b[33m7.53 GiB\u001b[39m, over \u001b[33m1442\u001b[39m allocations."
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD0pN-1mBCZL"
      },
      "source": [
        "# now do a simple LBFGS using library. The custom LBFGS is in Python\n",
        "The More Thuente line search seems to work best"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEpn2CmwBNzO",
        "outputId": "c98194f7-76b6-42f0-a9a6-ab0950485886"
      },
      "source": [
        "using Pkg; Pkg.add(\"Optim\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DiffRules ────────────── v1.3.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FiniteDiff ───────────── v2.8.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OpenSpecFun_jll ──────── v0.5.5+0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Static ───────────────── v0.3.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IfElse ───────────────── v0.1.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ArrayInterface ───────── v3.1.24\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LogExpFunctions ──────── v0.3.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Optim ────────────────── v1.4.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PositiveFactorizations ─ v0.2.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FillArrays ───────────── v0.12.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Parameters ───────────── v0.12.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IrrationalConstants ──── v0.1.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NLSolversBase ────────── v7.8.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ForwardDiff ──────────── v0.10.19\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SpecialFunctions ─────── v1.6.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChainRulesCore ───────── v1.3.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CommonSubexpressions ─── v0.3.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LineSearches ─────────── v7.1.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DocStringExtensions ──── v0.8.5\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m UnPack ───────────────── v1.0.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DiffResults ──────────── v1.0.3\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Project.toml`\n",
            " \u001b[90m [429524aa] \u001b[39m\u001b[92m+ Optim v1.4.1\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Manifest.toml`\n",
            " \u001b[90m [4fba245c] \u001b[39m\u001b[92m+ ArrayInterface v3.1.24\u001b[39m\n",
            " \u001b[90m [d360d2e6] \u001b[39m\u001b[92m+ ChainRulesCore v1.3.0\u001b[39m\n",
            " \u001b[90m [bbf7d656] \u001b[39m\u001b[92m+ CommonSubexpressions v0.3.0\u001b[39m\n",
            " \u001b[90m [163ba53b] \u001b[39m\u001b[92m+ DiffResults v1.0.3\u001b[39m\n",
            " \u001b[90m [b552c78f] \u001b[39m\u001b[92m+ DiffRules v1.3.0\u001b[39m\n",
            " \u001b[90m [ffbed154] \u001b[39m\u001b[92m+ DocStringExtensions v0.8.5\u001b[39m\n",
            " \u001b[90m [1a297f60] \u001b[39m\u001b[92m+ FillArrays v0.12.2\u001b[39m\n",
            " \u001b[90m [6a86dc24] \u001b[39m\u001b[92m+ FiniteDiff v2.8.1\u001b[39m\n",
            " \u001b[90m [f6369f11] \u001b[39m\u001b[92m+ ForwardDiff v0.10.19\u001b[39m\n",
            " \u001b[90m [615f187c] \u001b[39m\u001b[92m+ IfElse v0.1.0\u001b[39m\n",
            " \u001b[90m [92d709cd] \u001b[39m\u001b[92m+ IrrationalConstants v0.1.0\u001b[39m\n",
            " \u001b[90m [d3d80556] \u001b[39m\u001b[92m+ LineSearches v7.1.1\u001b[39m\n",
            " \u001b[90m [2ab3a3ac] \u001b[39m\u001b[92m+ LogExpFunctions v0.3.0\u001b[39m\n",
            " \u001b[90m [d41bc354] \u001b[39m\u001b[92m+ NLSolversBase v7.8.1\u001b[39m\n",
            " \u001b[90m [429524aa] \u001b[39m\u001b[92m+ Optim v1.4.1\u001b[39m\n",
            " \u001b[90m [d96e819e] \u001b[39m\u001b[92m+ Parameters v0.12.2\u001b[39m\n",
            " \u001b[90m [85a6dd25] \u001b[39m\u001b[92m+ PositiveFactorizations v0.2.4\u001b[39m\n",
            " \u001b[90m [276daf66] \u001b[39m\u001b[92m+ SpecialFunctions v1.6.1\u001b[39m\n",
            " \u001b[90m [aedffcd0] \u001b[39m\u001b[92m+ Static v0.3.0\u001b[39m\n",
            " \u001b[90m [3a884ed6] \u001b[39m\u001b[92m+ UnPack v1.0.2\u001b[39m\n",
            " \u001b[90m [efe28fd5] \u001b[39m\u001b[92m+ OpenSpecFun_jll v0.5.5+0\u001b[39m\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mUnPack\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mDocStringExtensions\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mPositiveFactorizations\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mIfElse\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mFillArrays\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mIrrationalConstants\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mChainRulesCore\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mCommonSubexpressions\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mDiffResults\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenSpecFun_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mParameters\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mStatic\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mLogExpFunctions\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mFiniteDiff\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mSpecialFunctions\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mDiffRules\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mForwardDiff\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mNLSolversBase\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mLineSearches\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39mOptim\n",
            "21 dependencies successfully precompiled in 30 seconds (123 already precompiled)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c4q5DjBb6Mr",
        "outputId": "f61ca169-7c05-41e4-a187-0c4b3e101546"
      },
      "source": [
        "using Optim\n",
        "function veca(mat)\n",
        "  # vectorize antisymmetric matrices\n",
        "  sz = size(mat)[1]\n",
        "  ret = zeros(div((sz*(sz-1)), 2))\n",
        "  start = 1\n",
        "  for i in 1:sz-1\n",
        "    # println(size(ret[start:start+sz-i-1]), size(mat[i+1:end, i]))\n",
        "    ret[start:start+sz-i-1] = mat[i+1:end, i]\n",
        "    start += sz-i\n",
        "  end\n",
        "  return ret\n",
        "end\n",
        "\n",
        "function unveca(v)\n",
        "   sz = .5 * (1 + sqrt(1 + 8 * size(v)[1]))\n",
        "   sz = Int(round(sz))\n",
        "   mat = zeros(sz, sz)\n",
        "   start = 1\n",
        "   for i in 1:(sz-1)\n",
        "     mat[i+1:end, i] = v[start:start+sz-i-1]\n",
        "     mat[i, i+1:end] = - v[start:start+sz-i-1]\n",
        "    start += sz-i\n",
        "  end\n",
        "  return mat\n",
        "end\n",
        "\n",
        "function rlog_lbfgs(stf, Y, Z, tol)\n",
        "  alf = stf.alpha[2]/stf.alpha[1]\n",
        "  n, p = stf.n, stf.p\n",
        "\n",
        "  Q = get_Q(Y, Y1)\n",
        "  k = size(Q, 2)\n",
        "\n",
        "  eta0 = stf_proj(stf, Y, Y1-Y)\n",
        "  A = asym(Y' * eta0)\n",
        "  R = Q' * eta0 - (Q' * Y) * (Y' * eta0)\n",
        "  Adim = div(p*(p-1), 2)\n",
        "\n",
        "  ZTY = Y1'*Y\n",
        "  ZTQ = Y1'*Q\n",
        "  function  ARunvec(v)\n",
        "    return  unveca(v[1:Adim]), reshape(v[Adim+1:end], k, p)\n",
        "  end\n",
        "  \n",
        "  function fun!(F, G, v)\n",
        "    # to make this cheap, ie p^3 cost only evaluate ZTY, ZTQ outside\n",
        "    # and evaluate both function and gradient\n",
        "      A, R = ARunvec(v)\n",
        "      ex1 = exp((1-2*alf)*A)\n",
        "\n",
        "      mat = vcat([(2*alf*A) -R'], [R zeros(k, k)])\n",
        "      E = vcat([(ex1 * ZTY) ex1*ZTQ], zeros(k, p+k))\n",
        "\n",
        "      if G == nothing\n",
        "        ex2 =  exp(mat)\n",
        "        M = ex2[1:p, 1:p]\n",
        "        N = ex2[p+1:end, 1:p]\n",
        "        \n",
        "        return -sum(( ZTY*M+ZTQ*N)' .* ex1)\n",
        "      end\n",
        "      ex2, fe2 = expm_frechet_algo_64(mat, E)\n",
        "      M = ex2[1:p, 1:p]\n",
        "      N = ex2[p+1:end, 1:p]\n",
        "      ZYMQN = ZTY*M+ZTQ*N\n",
        "\n",
        "      partA = asym(\n",
        "          (1-2*alf)*expm_frechet_algo_64((1-2*alf)*A, ZYMQN)[2])\n",
        "\n",
        "      partA += 2*alf*asym(fe2[1:p, 1:p])\n",
        "      partR = -(fe2[1:p, p+1:end]' - fe2[p+1:end, 1:p])\n",
        "      \n",
        "      G[1:Adim] = veca(partA)\n",
        "      G[1+Adim:end] = vec(partR)       \n",
        "      return -sum(ZYMQN' .* ex1)\n",
        "  end\n",
        "  v0 = vcat(veca(A), vec(R))\n",
        "  optzer = LBFGS(linesearch = Optim.LineSearches.MoreThuente(), m=5)\n",
        "  ret = optimize(Optim.only_fg!(fun!), v0, optzer)\n",
        "  A, R = ARunvec(Optim.minimizer(ret))  \n",
        "  \n",
        "  return Y * A + Q*R, ret\n",
        "end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rlog_lbfgs (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXEcvPaAwwat",
        "outputId": "25af7499-589b-4c5f-c03a-3ca0fb53eb1a"
      },
      "source": [
        "n = 7\n",
        "p = 3\n",
        "alpha = [1, 0.5]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = stf_rand(M2)\n",
        "xi = stf_randvec(M2, Y)*.5*pi\n",
        "Y1 = stf_exp(M2, Y, xi)\n",
        "\n",
        "eta1, ret = rlog_lbfgs(M2, Y, Y1, 1e-8)\n",
        "println(linf(stf_exp(M2, Y, eta1) - Y1))\n",
        "print(ret)\n",
        "\n",
        "if true\n",
        "  @benchmark rlog_lbfgs(M2, Y, Y1, 1e-8)\n",
        "end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.905688242937359e-9\n",
            " * Status: success\n",
            "\n",
            " * Candidate solution\n",
            "    Final objective value:     -3.000000e+00\n",
            "\n",
            " * Found with\n",
            "    Algorithm:     L-BFGS\n",
            "\n",
            " * Convergence measures\n",
            "    |x - x'|               = 6.15e-08 ≰ 0.0e+00\n",
            "    |x - x'|/|x'|          = 6.48e-08 ≰ 0.0e+00\n",
            "    |f(x) - f(x')|         = 5.33e-15 ≰ 0.0e+00\n",
            "    |f(x) - f(x')|/|f(x')| = 1.78e-15 ≰ 0.0e+00\n",
            "    |g(x)|                 = 5.36e-09 ≤ 1.0e-08\n",
            "\n",
            " * Work counters\n",
            "    Seconds run:   0  (vs limit Inf)\n",
            "    Iterations:    13\n",
            "    f(x) calls:    14\n",
            "    ∇f(x) calls:   14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 3595 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.025 ms\u001b[22m\u001b[39m … \u001b[35m 14.461 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 67.49%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.291 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.378 ms\u001b[22m\u001b[39m ± \u001b[32m649.229 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m3.94% ±  8.25%\n",
              "\n",
              "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\n",
              "  1.45 ms\u001b[90m         Histogram: frequency by time\u001b[39m        1.28 ms \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m653.02 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m3509\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8WmyckMMcSu",
        "outputId": "90805a3c-46e8-47c9-ef2e-438d5c1ab9f5"
      },
      "source": [
        "n = 1000\n",
        "p = 50\n",
        "alpha = [1, 0.5]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = stf_rand(M2)\n",
        "xi = stf_randvec(M2, Y)*.5*pi\n",
        "Y1 = stf_exp(M2, Y, xi)\n",
        "\n",
        "eta1, ret = rlog_lbfgs(M2, Y, Y1, 1e-8)\n",
        "println(linf(stf_exp(M2, Y, eta1) - Y1))\n",
        "print(ret)\n",
        "\n",
        "if true\n",
        "  @benchmark rlog_lbfgs(M2, Y, Y1, 1e-8)\n",
        "end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.142334018517822e-9\n",
            " * Status: success\n",
            "\n",
            " * Candidate solution\n",
            "    Final objective value:     -5.000000e+01\n",
            "\n",
            " * Found with\n",
            "    Algorithm:     L-BFGS\n",
            "\n",
            " * Convergence measures\n",
            "    |x - x'|               = 5.98e-08 ≰ 0.0e+00\n",
            "    |x - x'|/|x'|          = 2.59e-07 ≰ 0.0e+00\n",
            "    |f(x) - f(x')|         = 5.19e-13 ≰ 0.0e+00\n",
            "    |f(x) - f(x')|/|f(x')| = 1.04e-14 ≰ 0.0e+00\n",
            "    |g(x)|                 = 5.48e-09 ≤ 1.0e-08\n",
            "\n",
            " * Work counters\n",
            "    Seconds run:   0  (vs limit Inf)\n",
            "    Iterations:    5\n",
            "    f(x) calls:    6\n",
            "    ∇f(x) calls:   6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 82 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m56.198 ms\u001b[22m\u001b[39m … \u001b[35m94.033 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m8.62% … 17.05%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m60.122 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m7.99%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m61.211 ms\u001b[22m\u001b[39m ± \u001b[32m 5.128 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m9.47% ±  2.74%\n",
              "\n",
              "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[34m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▇\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[34m▁\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\n",
              "  56.9 ms\u001b[90m         Histogram: frequency by time\u001b[39m        60.7 ms \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m60.13 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m3959\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1ZVS_OfMg6v",
        "outputId": "c1b7ad6b-61ef-462d-d899-932d2e36e326"
      },
      "source": [
        "n = 1500\n",
        "p = 500\n",
        "alpha = [1, 0.5]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = stf_rand(M2)\n",
        "xi = stf_randvec(M2, Y)*.5*pi\n",
        "Y1 = stf_exp(M2, Y, xi)\n",
        "\n",
        "eta1, ret = rlog_lbfgs(M2, Y, Y1, 1e-8)\n",
        "println(linf(stf_exp(M2, Y, eta1) - Y1))\n",
        "print(ret)\n",
        "\n",
        "if true\n",
        "  @benchmark rlog_lbfgs(M2, Y, Y1, 1e-8)\n",
        "end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.3959612021647896e-9\n",
            " * Status: success\n",
            "\n",
            " * Candidate solution\n",
            "    Final objective value:     -5.000000e+02\n",
            "\n",
            " * Found with\n",
            "    Algorithm:     L-BFGS\n",
            "\n",
            " * Convergence measures\n",
            "    |x - x'|               = 2.16e-07 ≰ 0.0e+00\n",
            "    |x - x'|/|x'|          = 3.20e-06 ≰ 0.0e+00\n",
            "    |f(x) - f(x')|         = 2.37e-10 ≰ 0.0e+00\n",
            "    |f(x) - f(x')|/|f(x')| = 4.75e-13 ≰ 0.0e+00\n",
            "    |g(x)|                 = 7.59e-09 ≤ 1.0e-08\n",
            "\n",
            " * Work counters\n",
            "    Seconds run:   10  (vs limit Inf)\n",
            "    Iterations:    3\n",
            "    f(x) calls:    4\n",
            "    ∇f(x) calls:   4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 1 sample with 1 evaluation.\n",
              " Single result which took \u001b[34m15.367 s\u001b[39m (5.11% GC) to evaluate,\n",
              " with a memory estimate of \u001b[33m4.02 GiB\u001b[39m, over \u001b[33m11943\u001b[39m allocations."
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcQKgngpMkKT",
        "outputId": "2e8c09c5-e3cb-4710-9662-10d761ed2097"
      },
      "source": [
        "n = 1500\n",
        "p = 1000\n",
        "alpha = [1, 0.5]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = stf_rand(M2)\n",
        "xi = stf_randvec(M2, Y)*.5*pi\n",
        "Y1 = stf_exp(M2, Y, xi)\n",
        "\n",
        "eta1, ret = rlog_lbfgs(M2, Y, Y1, 1e-8)\n",
        "println(linf(stf_exp(M2, Y, eta1) - Y1))\n",
        "print(ret)\n",
        "\n",
        "if true\n",
        "  @benchmark rlog_lbfgs(M2, Y, Y1, 1e-8)\n",
        "end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3021776221487933e-9\n",
            " * Status: success\n",
            "\n",
            " * Candidate solution\n",
            "    Final objective value:     -1.000000e+03\n",
            "\n",
            " * Found with\n",
            "    Algorithm:     L-BFGS\n",
            "\n",
            " * Convergence measures\n",
            "    |x - x'|               = 9.74e-08 ≰ 0.0e+00\n",
            "    |x - x'|/|x'|          = 2.52e-06 ≰ 0.0e+00\n",
            "    |f(x) - f(x')|         = 1.19e-10 ≰ 0.0e+00\n",
            "    |f(x) - f(x')|/|f(x')| = 1.19e-13 ≰ 0.0e+00\n",
            "    |g(x)|                 = 2.85e-09 ≤ 1.0e-08\n",
            "\n",
            " * Work counters\n",
            "    Seconds run:   37  (vs limit Inf)\n",
            "    Iterations:    3\n",
            "    f(x) calls:    4\n",
            "    ∇f(x) calls:   4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 1 sample with 1 evaluation.\n",
              " Single result which took \u001b[34m55.512 s\u001b[39m (2.15% GC) to evaluate,\n",
              " with a memory estimate of \u001b[33m10.24 GiB\u001b[39m, over \u001b[33m22017\u001b[39m allocations."
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "271QJPWAYSJJ",
        "outputId": "47a91fad-c5e6-498b-a6f3-d518c274581a"
      },
      "source": [
        "@benchmark rlog_descent(M2, Y, Y1, 1e-8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 1 sample with 1 evaluation.\n",
              " Single result which took \u001b[34m42.793 s\u001b[39m (2.62% GC) to evaluate,\n",
              " with a memory estimate of \u001b[33m7.53 GiB\u001b[39m, over \u001b[33m1442\u001b[39m allocations."
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P_DjN6mMkI3",
        "outputId": "f5d8602e-34d3-4c6c-bcdb-cf88d26649b9"
      },
      "source": [
        "n = 1500\n",
        "p = 200\n",
        "alpha = [1, 0.8]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = stf_rand(M2)\n",
        "xi = stf_randvec(M2, Y)*1.3*pi\n",
        "Y1 = stf_exp(M2, Y, xi)\n",
        "\n",
        "eta1, ret = rlog_lbfgs(M2, Y, Y1, 1e-8)\n",
        "println(linf(stf_exp(M2, Y, eta1) - Y1))\n",
        "print(ret)\n",
        "\n",
        "if true\n",
        "  @benchmark rlog_lbfgs(M2, Y, Y1, 1e-8)  \n",
        "end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0925045723929614e-10\n",
            " * Status: success\n",
            "\n",
            " * Candidate solution\n",
            "    Final objective value:     -2.000000e+02\n",
            "\n",
            " * Found with\n",
            "    Algorithm:     L-BFGS\n",
            "\n",
            " * Convergence measures\n",
            "    |x - x'|               = 1.99e-08 ≰ 0.0e+00\n",
            "    |x - x'|/|x'|          = 6.89e-08 ≰ 0.0e+00\n",
            "    |f(x) - f(x')|         = 7.39e-13 ≰ 0.0e+00\n",
            "    |f(x) - f(x')|/|f(x')| = 3.69e-15 ≰ 0.0e+00\n",
            "    |g(x)|                 = 3.23e-10 ≤ 1.0e-08\n",
            "\n",
            " * Work counters\n",
            "    Seconds run:   1  (vs limit Inf)\n",
            "    Iterations:    5\n",
            "    f(x) calls:    6\n",
            "    ∇f(x) calls:   6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 3 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.863 s\u001b[22m\u001b[39m … \u001b[35m  1.882 s\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m3.86% … 3.87%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.879 s              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m3.88%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.875 s\u001b[22m\u001b[39m ± \u001b[32m10.098 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m3.95% ± 0.15%\n",
              "\n",
              "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\n",
              "  1.88 s\u001b[90m         Histogram: frequency by time\u001b[39m        1.86 s \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.12 GiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m9480\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpoG3XCyaD4o",
        "outputId": "deb14afd-81af-4213-cfcd-a48d33a5c7f3"
      },
      "source": [
        "@benchmark rlog_descent(M2, Y, Y1, 1e-8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 4 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.312 s\u001b[22m\u001b[39m … \u001b[35m  1.372 s\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m3.73% … 3.38%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.337 s              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m3.46%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.339 s\u001b[22m\u001b[39m ± \u001b[32m24.858 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m3.50% ± 0.16%\n",
              "\n",
              "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\n",
              "  1.37 s\u001b[90m         Histogram: frequency by time\u001b[39m        1.31 s \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m774.12 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m2530\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K42g_HCERk4c",
        "outputId": "82a03902-80a9-49f1-e327-c89baeda12c7"
      },
      "source": [
        "n = 7\n",
        "p = 3\n",
        "alpha = [1, 0.8]\n",
        "M2 = Stf(n, p, alpha)\n",
        "Y = stf_rand(M2)\n",
        "xi = stf_randvec(M2, Y)*1.3*pi\n",
        "Y1 = stf_exp(M2, Y, xi)\n",
        "\n",
        "eta1, ret = rlog_lbfgs(M2, Y, Y1, 1e-8)\n",
        "println(linf(stf_exp(M2, Y, eta1) - Y1))\n",
        "print(ret)\n",
        "\n",
        "if true\n",
        "  @benchmark rlog_lbfgs(M2, Y, Y1, 1e-8)  \n",
        "end\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08462418124997292\n",
            " * Status: success\n",
            "\n",
            " * Candidate solution\n",
            "    Final objective value:     -2.994179e+00\n",
            "\n",
            " * Found with\n",
            "    Algorithm:     L-BFGS\n",
            "\n",
            " * Convergence measures\n",
            "    |x - x'|               = 0.00e+00 ≤ 0.0e+00\n",
            "    |x - x'|/|x'|          = 0.00e+00 ≤ 0.0e+00\n",
            "    |f(x) - f(x')|         = 0.00e+00 ≤ 0.0e+00\n",
            "    |f(x) - f(x')|/|f(x')| = 0.00e+00 ≤ 0.0e+00\n",
            "    |g(x)|                 = 1.50e-02 ≰ 1.0e-08\n",
            "\n",
            " * Work counters\n",
            "    Seconds run:   0  (vs limit Inf)\n",
            "    Iterations:    18\n",
            "    f(x) calls:    64\n",
            "    ∇f(x) calls:   64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 714 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m5.700 ms\u001b[22m\u001b[39m … \u001b[35m24.562 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 59.43%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m6.375 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m6.991 ms\u001b[22m\u001b[39m ± \u001b[32m 2.044 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m5.13% ± 10.17%\n",
              "\n",
              "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▁\n",
              "  8.23 ms\u001b[90m        Histogram: frequency by time\u001b[39m        6.08 ms \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m3.51 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m20501\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfB6gjwmSnxW",
        "outputId": "8ebea911-54f3-456b-f8df-5dc6282494a7"
      },
      "source": [
        "eta1, ret = rlog_descent(M2, Y, Y1, 1e-8)\n",
        "println(ret)\n",
        "println(linf(stf_exp(M2, Y, eta1) - Y1))\n",
        "@benchmark rlog_descent(M2, Y, Y1, 1e-8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120\n",
            "0.07811664045523886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: 394 samples with 1 evaluation.\n",
              " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m10.171 ms\u001b[22m\u001b[39m … \u001b[35m33.486 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 16.78%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m11.498 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
              " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m12.675 ms\u001b[22m\u001b[39m ± \u001b[32m 3.106 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m5.32% ±  9.64%\n",
              "\n",
              "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
              "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▆\n",
              "  16.2 ms\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      13.6 ms \u001b[0m\u001b[1m<\u001b[22m\n",
              "\n",
              " Memory estimate\u001b[90m: \u001b[39m\u001b[33m6.45 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m37203\u001b[39m."
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akokuIvthIvf"
      },
      "source": [
        "# SHOW THE GRADIENT WORKS ON THE SPHERE\n",
        "Agreeing with trigonometry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDAcozKklgHZ",
        "outputId": "7a964934-cfff-4922-fb00-41ca440b1e22"
      },
      "source": [
        "function randsphere(n)\n",
        "  x = randn(n)\n",
        "  return x/norm(x, 2)\n",
        "end  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "randsphere (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CrLeTA4lw1m",
        "outputId": "bd1ceab6-0a6e-4da4-fd63-09bd7d64aab1"
      },
      "source": [
        "n = 5\n",
        "y = randsphere(n)\n",
        "z = randsphere(n)\n",
        "q = z - y*sum(y .* z)\n",
        "q = q / norm(q, 2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5-element Vector{Float64}:\n",
              "  0.42801599283627284\n",
              "  0.12918024834403197\n",
              " -0.5777275486806889\n",
              " -0.40168210721849473\n",
              "  0.5522654593128796"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKbplnf5mPUL",
        "outputId": "6e75b57e-3b13-4889-cdc2-f000c6cf80f9"
      },
      "source": [
        "r = .6\n",
        "zty = sum(z .* y)\n",
        "ztq = sum(z .* q)\n",
        "function fcost(r)\n",
        "  return - zty*cos(r) - ztq*sin(r)\n",
        "end  \n",
        "\n",
        "A= reshape([0, r, -r, 0], (2, 2))\n",
        "E = reshape([zty, ztq, 0, 0], (2, 2))'\n",
        "println(E)\n",
        "s = expm_frechet_algo_64(A, E)[2]\n",
        "hh = 1e-7\n",
        "println((fcost(r+hh) - fcost(r))/hh)\n",
        "println( zty*sin(r) - ztq*cos(r))\n",
        "println(s[2, 1] - s[1, 2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.7555460671575899 0.6550955200600131; 0.0 0.0]\n",
            "-0.9672870771026965\n",
            "-0.9672870639970595\n",
            "-0.9672870639970592\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}